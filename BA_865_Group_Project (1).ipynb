{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PW909otr4HTp",
        "juNQf_0T4RxO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Sea Surface Temperatures"
      ],
      "metadata": {
        "id": "l6XPrsAid0Qw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up"
      ],
      "metadata": {
        "id": "KfgbtwEHihaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uh4xWnoDby-P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U2u5F6EOGuH1"
      },
      "outputs": [],
      "source": [
        "# Reading the data\n",
        "sea_temp = pd.read_csv(\"/content/Average_Sea_Surface_Temps.csv\")\n",
        "sea_variables = pd.read_csv(\"/content/Avg_Variables.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data overview\n",
        "sea_temp.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NreDEJmOgLh",
        "outputId": "e268c3a0-3241-40fd-f41a-a8345646a5a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 345646 entries, 0 to 345645\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   month                 345646 non-null  int64  \n",
            " 1   day                   345646 non-null  int64  \n",
            " 2   timestamp             345646 non-null  object \n",
            " 3   avg_sea_surface_temp  345646 non-null  float64\n",
            "dtypes: float64(1), int64(2), object(1)\n",
            "memory usage: 10.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop missing row\n",
        "sea_temp.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "I9isVL5EXxKM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to datetime\n",
        "sea_temp['timestamp'] = pd.to_datetime(sea_temp['timestamp'])"
      ],
      "metadata": {
        "id": "CL8PSKMmXgCV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check summary statistics\n",
        "sea_temp.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "J9zbBKBMOZrh",
        "outputId": "f811f2a2-e958-49fb-c0e0-7691b53244b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               month            day  avg_sea_surface_temp\n",
              "count  345646.000000  345646.000000         345646.000000\n",
              "mean        6.502367      15.718996             20.237942\n",
              "std         3.442440       8.796251              4.103446\n",
              "min         1.000000       1.000000              0.200000\n",
              "25%         4.000000       8.000000             17.409664\n",
              "50%         7.000000      16.000000             20.675676\n",
              "75%         9.000000      23.000000             23.308325\n",
              "max        12.000000      31.000000             33.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6f7d48e-5342-40ba-8f03-e8015b2ca6be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>avg_sea_surface_temp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>345646.000000</td>\n",
              "      <td>345646.000000</td>\n",
              "      <td>345646.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>6.502367</td>\n",
              "      <td>15.718996</td>\n",
              "      <td>20.237942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.442440</td>\n",
              "      <td>8.796251</td>\n",
              "      <td>4.103446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>17.409664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>20.675676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>23.308325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>33.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6f7d48e-5342-40ba-8f03-e8015b2ca6be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6f7d48e-5342-40ba-8f03-e8015b2ca6be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6f7d48e-5342-40ba-8f03-e8015b2ca6be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-235778de-84ca-4026-a2a8-0bd934aaf2f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-235778de-84ca-4026-a2a8-0bd934aaf2f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-235778de-84ca-4026-a2a8-0bd934aaf2f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"sea_temp\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122202.14625244617,\n        \"min\": 1.0,\n        \"max\": 345646.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.502366583151548,\n          7.0,\n          345646.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122199.08728896911,\n        \"min\": 1.0,\n        \"max\": 345646.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15.718995735521315,\n          16.0,\n          345646.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sea_surface_temp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 122198.30856695409,\n        \"min\": 0.2,\n        \"max\": 345646.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20.237942220762164,\n          20.675675675675677,\n          345646.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = sea_temp[['avg_sea_surface_temp']]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_data = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "OqHOsdyFaLDh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "split_ratio = 0.8\n",
        "train_size = int(len(sea_temp) * split_ratio)"
      ],
      "metadata": {
        "id": "f_2Ld5Azbj41"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Variable MLP"
      ],
      "metadata": {
        "id": "PW909otr4HTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1\n",
        "\n",
        "lr = 0.0001\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 49"
      ],
      "metadata": {
        "id": "cRGV7jutevmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 49\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "UFGDewUxjbog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "ss_6HdbKjbog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 20),\n",
        "          nn.Linear(20, 10),\n",
        "          nn.Linear(10, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "amY2eh1Hjbog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1 Parameters\n",
        "\n",
        "lr = 0.0001\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "myFOk8qDeh88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "rvgzgVtndIbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9WqfsvPc-eV",
        "outputId": "681183b6-8a4b-43b2-c7b7-e3068ab9533f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 22.45330124147956, Test Actual Error= 21.19702731447268\n",
            "Epoch 10: Training Actual Error= 21.831552531370942, Test Actual Error= 20.510239049424204\n",
            "Epoch 20: Training Actual Error= 20.648876386816163, Test Actual Error= 19.337201653328183\n",
            "Epoch 30: Training Actual Error= 19.288882586416268, Test Actual Error= 18.011851005306102\n",
            "Epoch 40: Training Actual Error= 17.88191932958824, Test Actual Error= 16.64706751795244\n",
            "Epoch 50: Training Actual Error= 16.468716272339222, Test Actual Error= 15.277708502744442\n",
            "Epoch 60: Training Actual Error= 15.058684140565664, Test Actual Error= 13.911513924070514\n",
            "Epoch 70: Training Actual Error= 13.650717392203491, Test Actual Error= 12.546725514618144\n",
            "Epoch 80: Training Actual Error= 12.240749420632506, Test Actual Error= 11.178649491471392\n",
            "Epoch 90: Training Actual Error= 10.829766122469158, Test Actual Error= 9.803452842610076\n",
            "Epoch 100: Training Actual Error= 9.45922403468723, Test Actual Error= 8.433363402196361\n",
            "Epoch 110: Training Actual Error= 8.175070437008694, Test Actual Error= 7.098760160710748\n",
            "Epoch 120: Training Actual Error= 6.9877565103176975, Test Actual Error= 5.82533549956503\n",
            "Epoch 130: Training Actual Error= 5.9305117434542165, Test Actual Error= 4.677614003488949\n",
            "Epoch 140: Training Actual Error= 5.03028745864707, Test Actual Error= 3.7860718266294264\n",
            "Epoch 150: Training Actual Error= 4.320610204779817, Test Actual Error= 3.219458634321561\n",
            "Epoch 160: Training Actual Error= 3.8111468827803874, Test Actual Error= 2.9283010156274147\n",
            "Epoch 170: Training Actual Error= 3.481276691358002, Test Actual Error= 2.8458489491387815\n",
            "Epoch 180: Training Actual Error= 3.3043764954240737, Test Actual Error= 2.878401724184708\n",
            "Epoch 190: Training Actual Error= 3.229185036388148, Test Actual Error= 2.9464309984532666\n",
            "Epoch 200: Training Actual Error= 3.2034328516748074, Test Actual Error= 3.006618359226613\n",
            "Epoch 210: Training Actual Error= 3.1961077196385954, Test Actual Error= 3.045842465275846\n",
            "Epoch 220: Training Actual Error= 3.194211566601032, Test Actual Error= 3.0664050578144026\n",
            "Epoch 230: Training Actual Error= 3.1934000193947596, Test Actual Error= 3.0746553660271236\n",
            "Epoch 240: Training Actual Error= 3.1926665306612727, Test Actual Error= 3.076234505052798\n",
            "Epoch 250: Training Actual Error= 3.19189524916837, Test Actual Error= 3.0749105127111798\n",
            "Epoch 260: Training Actual Error= 3.191114089104063, Test Actual Error= 3.0727312426494118\n",
            "Epoch 270: Training Actual Error= 3.1903395544778355, Test Actual Error= 3.0706241189382313\n",
            "Epoch 280: Training Actual Error= 3.1895722367273347, Test Actual Error= 3.068881464536836\n",
            "Epoch 290: Training Actual Error= 3.1888095341704052, Test Actual Error= 3.067528986876088\n",
            "Epoch 300: Training Actual Error= 3.1880492456534797, Test Actual Error= 3.0664991900763745\n",
            "Epoch 310: Training Actual Error= 3.1872902781058876, Test Actual Error= 3.0656889579477027\n",
            "Epoch 320: Training Actual Error= 3.1865321355727954, Test Actual Error= 3.0649879067671413\n",
            "Epoch 330: Training Actual Error= 3.1857748031621944, Test Actual Error= 3.0643312365745397\n",
            "Epoch 340: Training Actual Error= 3.185018250283946, Test Actual Error= 3.063689844060292\n",
            "Epoch 350: Training Actual Error= 3.184262479589761, Test Actual Error= 3.0630484130224036\n",
            "Epoch 360: Training Actual Error= 3.183507466690968, Test Actual Error= 3.0624114374613765\n",
            "Epoch 370: Training Actual Error= 3.18275317496567, Test Actual Error= 3.0617679123439894\n",
            "Epoch 380: Training Actual Error= 3.18199991613488, Test Actual Error= 3.0611121924294813\n",
            "Epoch 390: Training Actual Error= 3.1812475668162494, Test Actual Error= 3.0604499887203347\n",
            "Epoch 400: Training Actual Error= 3.1804961978458204, Test Actual Error= 3.059801006115438\n",
            "Epoch 410: Training Actual Error= 3.179745736336894, Test Actual Error= 3.0591596832661883\n",
            "Epoch 420: Training Actual Error= 3.1789961716083783, Test Actual Error= 3.05851561251036\n",
            "Epoch 430: Training Actual Error= 3.178247435833038, Test Actual Error= 3.05786611399415\n",
            "Epoch 440: Training Actual Error= 3.1774995143027165, Test Actual Error= 3.057191203564698\n",
            "Epoch 450: Training Actual Error= 3.1767524181121725, Test Actual Error= 3.0564992297362292\n",
            "Epoch 460: Training Actual Error= 3.176006097861795, Test Actual Error= 3.0558187405914237\n",
            "Epoch 470: Training Actual Error= 3.175260611090181, Test Actual Error= 3.0551557662397517\n",
            "Epoch 480: Training Actual Error= 3.1745159894764385, Test Actual Error= 3.054504625123011\n",
            "Epoch 490: Training Actual Error= 3.173772237910322, Test Actual Error= 3.053857413247935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 49"
      ],
      "metadata": {
        "id": "SVKlmd0jgbz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 49\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "WeF3fuz7jRKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "1iN4j3KejT0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 20),\n",
        "          nn.Linear(20, 10),\n",
        "          nn.Linear(10, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "NY_SV5E5jWfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 Parameters\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "pOgGIom3gbz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "1IoWq-KPgbz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61869853-49a7-4fa5-f351-f97abfaeeb30",
        "id": "8w9xOEOvgbz9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 17.53795744536497, Test Actual Error= 14.405030491332678\n",
            "Epoch 10: Training Actual Error= 4.811422331832247, Test Actual Error= 5.616880186946321\n",
            "Epoch 20: Training Actual Error= 3.4549581636838567, Test Actual Error= 2.9233915666357126\n",
            "Epoch 30: Training Actual Error= 3.620495761442022, Test Actual Error= 3.7498279578491385\n",
            "Epoch 40: Training Actual Error= 3.1088762167873276, Test Actual Error= 3.333050749512061\n",
            "Epoch 50: Training Actual Error= 3.1084706942287523, Test Actual Error= 2.941747689385536\n",
            "Epoch 60: Training Actual Error= 3.063041389141574, Test Actual Error= 2.886245172629219\n",
            "Epoch 70: Training Actual Error= 3.017299736776088, Test Actual Error= 2.931553160899784\n",
            "Epoch 80: Training Actual Error= 2.988841576219572, Test Actual Error= 2.9560964075314673\n",
            "Epoch 90: Training Actual Error= 2.9564067539131944, Test Actual Error= 2.932826115724682\n",
            "Epoch 100: Training Actual Error= 2.9232118519457297, Test Actual Error= 2.892908353959124\n",
            "Epoch 110: Training Actual Error= 2.889646109156283, Test Actual Error= 2.854912194478998\n",
            "Epoch 120: Training Actual Error= 2.8552121699703523, Test Actual Error= 2.8203912851998263\n",
            "Epoch 130: Training Actual Error= 2.8197563606618017, Test Actual Error= 2.788843390926184\n",
            "Epoch 140: Training Actual Error= 2.7834436731173806, Test Actual Error= 2.7581784185357563\n",
            "Epoch 150: Training Actual Error= 2.74668102723074, Test Actual Error= 2.7283903073575515\n",
            "Epoch 160: Training Actual Error= 2.7103613123831884, Test Actual Error= 2.7003964812823362\n",
            "Epoch 170: Training Actual Error= 2.6753178346899125, Test Actual Error= 2.674140399498951\n",
            "Epoch 180: Training Actual Error= 2.642033421300806, Test Actual Error= 2.6493750828584757\n",
            "Epoch 190: Training Actual Error= 2.610376458781524, Test Actual Error= 2.6268953282518\n",
            "Epoch 200: Training Actual Error= 2.5801533651538238, Test Actual Error= 2.606111196210625\n",
            "Epoch 210: Training Actual Error= 2.551487550797895, Test Actual Error= 2.5877191552286103\n",
            "Epoch 220: Training Actual Error= 2.5245331902844588, Test Actual Error= 2.5721256797951297\n",
            "Epoch 230: Training Actual Error= 2.499429151606168, Test Actual Error= 2.5596658764273372\n",
            "Epoch 240: Training Actual Error= 2.4762462637768303, Test Actual Error= 2.550149235750669\n",
            "Epoch 250: Training Actual Error= 2.4550059925286454, Test Actual Error= 2.5443312189497775\n",
            "Epoch 260: Training Actual Error= 2.435944498453433, Test Actual Error= 2.5411119603366523\n",
            "Epoch 270: Training Actual Error= 2.419128595549113, Test Actual Error= 2.540158029907918\n",
            "Epoch 280: Training Actual Error= 2.404437652156491, Test Actual Error= 2.5412233807330225\n",
            "Epoch 290: Training Actual Error= 2.391671582413682, Test Actual Error= 2.542695418535645\n",
            "Epoch 300: Training Actual Error= 2.380444830711837, Test Actual Error= 2.5439682050671046\n",
            "Epoch 310: Training Actual Error= 2.370410912439417, Test Actual Error= 2.544425304443144\n",
            "Epoch 320: Training Actual Error= 2.3612013594477523, Test Actual Error= 2.543814801637997\n",
            "Epoch 330: Training Actual Error= 2.3526264396400607, Test Actual Error= 2.5424829781642697\n",
            "Epoch 340: Training Actual Error= 2.344591310453274, Test Actual Error= 2.5406988857038897\n",
            "Epoch 350: Training Actual Error= 2.337022018567458, Test Actual Error= 2.538577611852109\n",
            "Epoch 360: Training Actual Error= 2.329872643269035, Test Actual Error= 2.536333486929759\n",
            "Epoch 370: Training Actual Error= 2.323126851499031, Test Actual Error= 2.534054098026568\n",
            "Epoch 380: Training Actual Error= 2.316753915052399, Test Actual Error= 2.531649379811715\n",
            "Epoch 390: Training Actual Error= 2.310722359202007, Test Actual Error= 2.529292502316077\n",
            "Epoch 400: Training Actual Error= 2.304992530063788, Test Actual Error= 2.527011929546327\n",
            "Epoch 410: Training Actual Error= 2.2995602604719756, Test Actual Error= 2.524724891819491\n",
            "Epoch 420: Training Actual Error= 2.29441418106495, Test Actual Error= 2.5224548658015444\n",
            "Epoch 430: Training Actual Error= 2.289525387656038, Test Actual Error= 2.5202377612110123\n",
            "Epoch 440: Training Actual Error= 2.28489579762506, Test Actual Error= 2.5180233479154084\n",
            "Epoch 450: Training Actual Error= 2.280488046978374, Test Actual Error= 2.515705052440106\n",
            "Epoch 460: Training Actual Error= 2.276295616303917, Test Actual Error= 2.5134934228452575\n",
            "Epoch 470: Training Actual Error= 2.272308435741147, Test Actual Error= 2.5112026090803554\n",
            "Epoch 480: Training Actual Error= 2.26850307530817, Test Actual Error= 2.508943226858715\n",
            "Epoch 490: Training Actual Error= 2.264871609790046, Test Actual Error= 2.506643560095259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 100"
      ],
      "metadata": {
        "id": "Dvv5srx-jlRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 100\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "qTvzRxcQjlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "BRhC52JmjlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 20),\n",
        "          nn.Linear(20, 10),\n",
        "          nn.Linear(10, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "tDCrb-eqjlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3 Parameters\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "bQlTML3ejlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "AVy7_STrjlRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39325e9c-1a49-49db-bc3f-cc7870cb948c",
        "id": "DyBUmanSjlRC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 7.462508916412034, Test Actual Error= 5.428122023448139\n",
            "Epoch 10: Training Actual Error= 3.7325993992950175, Test Actual Error= 3.224638116250437\n",
            "Epoch 20: Training Actual Error= 3.2160645525342955, Test Actual Error= 3.0916808997818013\n",
            "Epoch 30: Training Actual Error= 3.226903514645619, Test Actual Error= 3.545504198002325\n",
            "Epoch 40: Training Actual Error= 3.086976513391635, Test Actual Error= 3.113865198747257\n",
            "Epoch 50: Training Actual Error= 3.0744560169641026, Test Actual Error= 2.9666427670618227\n",
            "Epoch 60: Training Actual Error= 3.026772879807613, Test Actual Error= 3.005127954886405\n",
            "Epoch 70: Training Actual Error= 2.9968866525642497, Test Actual Error= 3.039240457755735\n",
            "Epoch 80: Training Actual Error= 2.9625745331080386, Test Actual Error= 3.0195279496966827\n",
            "Epoch 90: Training Actual Error= 2.9265157010906893, Test Actual Error= 2.981616787630075\n",
            "Epoch 100: Training Actual Error= 2.88922595903435, Test Actual Error= 2.9451509850806734\n",
            "Epoch 110: Training Actual Error= 2.850099548356204, Test Actual Error= 2.9122879114474074\n",
            "Epoch 120: Training Actual Error= 2.8089555682834373, Test Actual Error= 2.880943968076727\n",
            "Epoch 130: Training Actual Error= 2.7658958428706177, Test Actual Error= 2.849133112457567\n",
            "Epoch 140: Training Actual Error= 2.7212787565435517, Test Actual Error= 2.817073132987047\n",
            "Epoch 150: Training Actual Error= 2.6756840364620054, Test Actual Error= 2.785280455576064\n",
            "Epoch 160: Training Actual Error= 2.630178644985052, Test Actual Error= 2.7549973669306205\n",
            "Epoch 170: Training Actual Error= 2.585690560622656, Test Actual Error= 2.7253186996193386\n",
            "Epoch 180: Training Actual Error= 2.542952802486909, Test Actual Error= 2.6972736262210004\n",
            "Epoch 190: Training Actual Error= 2.502789377751578, Test Actual Error= 2.669950810216767\n",
            "Epoch 200: Training Actual Error= 2.4656239326216154, Test Actual Error= 2.645640098662318\n",
            "Epoch 210: Training Actual Error= 2.4320407943849034, Test Actual Error= 2.62460704628051\n",
            "Epoch 220: Training Actual Error= 2.4026485293011, Test Actual Error= 2.6072437703536155\n",
            "Epoch 230: Training Actual Error= 2.3776140587522314, Test Actual Error= 2.592980080845645\n",
            "Epoch 240: Training Actual Error= 2.3568139408998836, Test Actual Error= 2.5820381223171354\n",
            "Epoch 250: Training Actual Error= 2.3395670148416947, Test Actual Error= 2.5722700478561946\n",
            "Epoch 260: Training Actual Error= 2.3250081253712285, Test Actual Error= 2.5635350771845378\n",
            "Epoch 270: Training Actual Error= 2.3123423803395515, Test Actual Error= 2.554713285679048\n",
            "Epoch 280: Training Actual Error= 2.3009589380114917, Test Actual Error= 2.545739495571141\n",
            "Epoch 290: Training Actual Error= 2.290494141176352, Test Actual Error= 2.536862938506285\n",
            "Epoch 300: Training Actual Error= 2.280777014843145, Test Actual Error= 2.528199178141099\n",
            "Epoch 310: Training Actual Error= 2.2717154567569353, Test Actual Error= 2.520007601171805\n",
            "Epoch 320: Training Actual Error= 2.263234968060526, Test Actual Error= 2.512224326838617\n",
            "Epoch 330: Training Actual Error= 2.255307704635192, Test Actual Error= 2.504926694266497\n",
            "Epoch 340: Training Actual Error= 2.247877646398034, Test Actual Error= 2.4980391295597704\n",
            "Epoch 350: Training Actual Error= 2.240901932628031, Test Actual Error= 2.491669909119985\n",
            "Epoch 360: Training Actual Error= 2.234329440584668, Test Actual Error= 2.485681226434022\n",
            "Epoch 370: Training Actual Error= 2.228131266925245, Test Actual Error= 2.480032863125772\n",
            "Epoch 380: Training Actual Error= 2.2222593383165608, Test Actual Error= 2.474714055428145\n",
            "Epoch 390: Training Actual Error= 2.216671064205702, Test Actual Error= 2.4697569424208914\n",
            "Epoch 400: Training Actual Error= 2.211346226386196, Test Actual Error= 2.4650200313322794\n",
            "Epoch 410: Training Actual Error= 2.2062833258426666, Test Actual Error= 2.460496382617843\n",
            "Epoch 420: Training Actual Error= 2.201464559104392, Test Actual Error= 2.456221603651482\n",
            "Epoch 430: Training Actual Error= 2.1968653826036375, Test Actual Error= 2.4520543155376413\n",
            "Epoch 440: Training Actual Error= 2.192479561982023, Test Actual Error= 2.4480506646073406\n",
            "Epoch 450: Training Actual Error= 2.1882954674311423, Test Actual Error= 2.44427471265393\n",
            "Epoch 460: Training Actual Error= 2.184296462521132, Test Actual Error= 2.440717356980597\n",
            "Epoch 470: Training Actual Error= 2.180466923913627, Test Actual Error= 2.4373408169620303\n",
            "Epoch 480: Training Actual Error= 2.1767967552735072, Test Actual Error= 2.4341170415049813\n",
            "Epoch 490: Training Actual Error= 2.173283636071308, Test Actual Error= 2.430938314706143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far this is the best model"
      ],
      "metadata": {
        "id": "hLXN4d5TwAw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 100\n",
        "\n",
        "layers changed:\n",
        "          nn.Linear(input_size, 40),\n",
        "          nn.Linear(40, 20),\n",
        "          nn.Linear(20, 1)"
      ],
      "metadata": {
        "id": "cP8pp-KvkerA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 100\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "IRscgxQqkerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "BtoUfvvRkerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 40),\n",
        "          nn.Linear(40, 20),\n",
        "          nn.Linear(20, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "5F2E3TXQkerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 4 Parameters\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "xLp7JVG0kerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "pU276IGgkerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41e4365-3a9b-4460-c03f-f69987808a75",
        "id": "8cyTMWYgkerA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 24.136541951597682, Test Actual Error= 19.23670418343941\n",
            "Epoch 10: Training Actual Error= 10.268979494118796, Test Actual Error= 7.861134949079852\n",
            "Epoch 20: Training Actual Error= 4.8569921345065605, Test Actual Error= 2.94252055123416\n",
            "Epoch 30: Training Actual Error= 2.9921973156546464, Test Actual Error= 3.192271655218643\n",
            "Epoch 40: Training Actual Error= 3.119366621741424, Test Actual Error= 3.2010983003585594\n",
            "Epoch 50: Training Actual Error= 2.9482338820090797, Test Actual Error= 2.830103993862673\n",
            "Epoch 60: Training Actual Error= 2.8623569441710055, Test Actual Error= 2.736982449909881\n",
            "Epoch 70: Training Actual Error= 2.830896736675459, Test Actual Error= 2.746487756552097\n",
            "Epoch 80: Training Actual Error= 2.7782363329599216, Test Actual Error= 2.778138934260614\n",
            "Epoch 90: Training Actual Error= 2.7377138329538786, Test Actual Error= 2.7406659001484566\n",
            "Epoch 100: Training Actual Error= 2.693845817862434, Test Actual Error= 2.6978011359149545\n",
            "Epoch 110: Training Actual Error= 2.6513727669559715, Test Actual Error= 2.6886005544449447\n",
            "Epoch 120: Training Actual Error= 2.610101649761653, Test Actual Error= 2.6607597233269873\n",
            "Epoch 130: Training Actual Error= 2.569935264510474, Test Actual Error= 2.641715137953783\n",
            "Epoch 140: Training Actual Error= 2.530950463993235, Test Actual Error= 2.620247607086678\n",
            "Epoch 150: Training Actual Error= 2.4931676896546433, Test Actual Error= 2.6032545500146784\n",
            "Epoch 160: Training Actual Error= 2.4570189250247645, Test Actual Error= 2.586455656664966\n",
            "Epoch 170: Training Actual Error= 2.4231522842116076, Test Actual Error= 2.572587400837221\n",
            "Epoch 180: Training Actual Error= 2.392058072416272, Test Actual Error= 2.562365876481685\n",
            "Epoch 190: Training Actual Error= 2.3644885394568567, Test Actual Error= 2.554298631677215\n",
            "Epoch 200: Training Actual Error= 2.3407270013395673, Test Actual Error= 2.548112047595633\n",
            "Epoch 210: Training Actual Error= 2.320551893649877, Test Actual Error= 2.5421766532611922\n",
            "Epoch 220: Training Actual Error= 2.3032327650856024, Test Actual Error= 2.5359802833671696\n",
            "Epoch 230: Training Actual Error= 2.287930354753101, Test Actual Error= 2.5286009907685383\n",
            "Epoch 240: Training Actual Error= 2.274131646314407, Test Actual Error= 2.520344615184162\n",
            "Epoch 250: Training Actual Error= 2.2615993727469985, Test Actual Error= 2.51214767211642\n",
            "Epoch 260: Training Actual Error= 2.2501723214932974, Test Actual Error= 2.5040857712886315\n",
            "Epoch 270: Training Actual Error= 2.2397848895703163, Test Actual Error= 2.4965125566522595\n",
            "Epoch 280: Training Actual Error= 2.2303893120598453, Test Actual Error= 2.4894906218310475\n",
            "Epoch 290: Training Actual Error= 2.221846437538673, Test Actual Error= 2.483053808304822\n",
            "Epoch 300: Training Actual Error= 2.2140663780663163, Test Actual Error= 2.477172542029654\n",
            "Epoch 310: Training Actual Error= 2.2069687057180065, Test Actual Error= 2.471629188117079\n",
            "Epoch 320: Training Actual Error= 2.200439486373562, Test Actual Error= 2.466488990856569\n",
            "Epoch 330: Training Actual Error= 2.194396725108796, Test Actual Error= 2.4617322993017177\n",
            "Epoch 340: Training Actual Error= 2.188809455760064, Test Actual Error= 2.4571191810962167\n",
            "Epoch 350: Training Actual Error= 2.1836240953639763, Test Actual Error= 2.4528966257652725\n",
            "Epoch 360: Training Actual Error= 2.1787867029990786, Test Actual Error= 2.44880568713851\n",
            "Epoch 370: Training Actual Error= 2.174241937538877, Test Actual Error= 2.4450563588161884\n",
            "Epoch 380: Training Actual Error= 2.1699645928156457, Test Actual Error= 2.44140323651551\n",
            "Epoch 390: Training Actual Error= 2.16593366244931, Test Actual Error= 2.437903009795483\n",
            "Epoch 400: Training Actual Error= 2.162133481972672, Test Actual Error= 2.4345087309064612\n",
            "Epoch 410: Training Actual Error= 2.1585440174722255, Test Actual Error= 2.431241431509926\n",
            "Epoch 420: Training Actual Error= 2.155151612744393, Test Actual Error= 2.4281045633935667\n",
            "Epoch 430: Training Actual Error= 2.1519368965304726, Test Actual Error= 2.4250913245667425\n",
            "Epoch 440: Training Actual Error= 2.1488911535893154, Test Actual Error= 2.422269221807057\n",
            "Epoch 450: Training Actual Error= 2.1460049853155687, Test Actual Error= 2.419529076331587\n",
            "Epoch 460: Training Actual Error= 2.143263790764186, Test Actual Error= 2.4168934845490555\n",
            "Epoch 470: Training Actual Error= 2.1406615566632805, Test Actual Error= 2.4142324382368585\n",
            "Epoch 480: Training Actual Error= 2.138190938900836, Test Actual Error= 2.411623803934559\n",
            "Epoch 490: Training Actual Error= 2.135848986823296, Test Actual Error= 2.4091031214201983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4.5\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 100\n",
        "\n",
        "layers changed:\n",
        "          nn.Linear(input_size, 80),\n",
        "          nn.Linear(80, 60),\n",
        "          nn.Linear(60, 1)"
      ],
      "metadata": {
        "id": "YRMFJhJv2kO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 100\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "_tNXQOVz2kO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "F0LqLz-b2kO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 80),\n",
        "          nn.Linear(80, 60),\n",
        "          nn.Linear(60, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "uXfJS38T2kO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 4 Parameters\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "INYkDxHU2kO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "BnFXjnCc2kO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a370ce-f902-4e8f-9f6e-dbcce5743918",
        "id": "tSkaEgK_2kO8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 12.986954716124965, Test Actual Error= 8.59209168623479\n",
            "Epoch 10: Training Actual Error= 6.052610706770939, Test Actual Error= 2.802955639332752\n",
            "Epoch 20: Training Actual Error= 3.353795992081187, Test Actual Error= 2.969491170551183\n",
            "Epoch 30: Training Actual Error= 2.937998686767853, Test Actual Error= 3.19467274897567\n",
            "Epoch 40: Training Actual Error= 2.902318305521516, Test Actual Error= 3.1927043653770384\n",
            "Epoch 50: Training Actual Error= 2.8722794803072884, Test Actual Error= 3.0607607832374626\n",
            "Epoch 60: Training Actual Error= 2.810818730752756, Test Actual Error= 2.9157963080017906\n",
            "Epoch 70: Training Actual Error= 2.735806522829881, Test Actual Error= 2.789161533007848\n",
            "Epoch 80: Training Actual Error= 2.6719044607537366, Test Actual Error= 2.715984067739634\n",
            "Epoch 90: Training Actual Error= 2.6118737578490054, Test Actual Error= 2.7139232294561375\n",
            "Epoch 100: Training Actual Error= 2.556043719337751, Test Actual Error= 2.6741819768131525\n",
            "Epoch 110: Training Actual Error= 2.504145910341268, Test Actual Error= 2.6390241869875704\n",
            "Epoch 120: Training Actual Error= 2.4561870067332054, Test Actual Error= 2.6083366424323087\n",
            "Epoch 130: Training Actual Error= 2.41235387072907, Test Actual Error= 2.5854152088734677\n",
            "Epoch 140: Training Actual Error= 2.372739085496959, Test Actual Error= 2.5628092970971066\n",
            "Epoch 150: Training Actual Error= 2.337829316878872, Test Actual Error= 2.5454827250567202\n",
            "Epoch 160: Training Actual Error= 2.3081795902918003, Test Actual Error= 2.5331190762546916\n",
            "Epoch 170: Training Actual Error= 2.2842358044721336, Test Actual Error= 2.524104839509121\n",
            "Epoch 180: Training Actual Error= 2.2653051740645886, Test Actual Error= 2.5162872914588497\n",
            "Epoch 190: Training Actual Error= 2.2502003118950293, Test Actual Error= 2.5087683143024586\n",
            "Epoch 200: Training Actual Error= 2.2376498280028656, Test Actual Error= 2.5004537264488484\n",
            "Epoch 210: Training Actual Error= 2.226775083722019, Test Actual Error= 2.4914873377409363\n",
            "Epoch 220: Training Actual Error= 2.2171079602623327, Test Actual Error= 2.48240063776804\n",
            "Epoch 230: Training Actual Error= 2.208402107023499, Test Actual Error= 2.473768939424175\n",
            "Epoch 240: Training Actual Error= 2.200551886440534, Test Actual Error= 2.4659032922174178\n",
            "Epoch 250: Training Actual Error= 2.193382549045703, Test Actual Error= 2.4587829797356053\n",
            "Epoch 260: Training Actual Error= 2.1868115335101885, Test Actual Error= 2.4525181501589772\n",
            "Epoch 270: Training Actual Error= 2.180751348757607, Test Actual Error= 2.446798796022167\n",
            "Epoch 280: Training Actual Error= 2.1751320531195413, Test Actual Error= 2.4415978901698643\n",
            "Epoch 290: Training Actual Error= 2.1698924609510133, Test Actual Error= 2.436755533077716\n",
            "Epoch 300: Training Actual Error= 2.1649972626256226, Test Actual Error= 2.432237211324306\n",
            "Epoch 310: Training Actual Error= 2.1604203719490567, Test Actual Error= 2.4280823007066865\n",
            "Epoch 320: Training Actual Error= 2.156138086613474, Test Actual Error= 2.424132394339841\n",
            "Epoch 330: Training Actual Error= 2.1521308705071314, Test Actual Error= 2.420350623796014\n",
            "Epoch 340: Training Actual Error= 2.148381810316927, Test Actual Error= 2.416787564554136\n",
            "Epoch 350: Training Actual Error= 2.144886009830275, Test Actual Error= 2.413307684385609\n",
            "Epoch 360: Training Actual Error= 2.1416037830294874, Test Actual Error= 2.4100706314837907\n",
            "Epoch 370: Training Actual Error= 2.1385080681401147, Test Actual Error= 2.4069134461088852\n",
            "Epoch 380: Training Actual Error= 2.135586153542688, Test Actual Error= 2.4039862753251855\n",
            "Epoch 390: Training Actual Error= 2.1328379451016475, Test Actual Error= 2.401229017701357\n",
            "Epoch 400: Training Actual Error= 2.130254556571687, Test Actual Error= 2.3985959699927175\n",
            "Epoch 410: Training Actual Error= 2.127823234608665, Test Actual Error= 2.3960320960584447\n",
            "Epoch 420: Training Actual Error= 2.125527191315729, Test Actual Error= 2.393572549210445\n",
            "Epoch 430: Training Actual Error= 2.1233576587102148, Test Actual Error= 2.3912029223228357\n",
            "Epoch 440: Training Actual Error= 2.121309175152645, Test Actual Error= 2.3889711824155646\n",
            "Epoch 450: Training Actual Error= 2.1193750279086556, Test Actual Error= 2.3868640493281474\n",
            "Epoch 460: Training Actual Error= 2.1175468451580963, Test Actual Error= 2.384860257819271\n",
            "Epoch 470: Training Actual Error= 2.115818636400049, Test Actual Error= 2.382933269817031\n",
            "Epoch 480: Training Actual Error= 2.114191294193176, Test Actual Error= 2.3810391252691328\n",
            "Epoch 490: Training Actual Error= 2.112657149677044, Test Actual Error= 2.379206339231863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500\n",
        "sequence_length = 100\n",
        "\n",
        "layers changed:\n",
        "          nn.Linear(input_size, 20),\n",
        "          nn.Linear(20, 10),\n",
        "          nn.Linear(10, 1)\n",
        "\n",
        "Adding relu"
      ],
      "metadata": {
        "id": "QjWE8sZ6lCPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 100\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "zy76bKjIlCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "rBjFcm3SlCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the MLP model\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "      super(MLP, self).__init__()\n",
        "      self.model = nn.Sequential(\n",
        "          nn.Linear(input_size, 40),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(40, 20),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(20, 1)\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, input_size)\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = sequence_length\n",
        "model = MLP(input_size)"
      ],
      "metadata": {
        "id": "2vRiy6eZlCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 4 Parameters\n",
        "\n",
        "lr = 0.01\n",
        "momentum= 0.9\n",
        "epochs = 500"
      ],
      "metadata": {
        "id": "FlS7Ci3ilCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion_training = nn.L1Loss()\n",
        "criterion_testing = nn.L1Loss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
      ],
      "metadata": {
        "id": "tHYb6CzclCPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting the y data in the correct format\n",
        "\n",
        "y_test_actual = torch.tensor(scaler.inverse_transform(y_test))\n",
        "y_train_actual = torch.tensor(scaler.inverse_transform(y_train))\n",
        "\n",
        "# Initializing a best model for later use\n",
        "best_test_error = torch.tensor(float(500))\n",
        "best_model_state = None\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    model.train()\n",
        "    pred = model(X_train)\n",
        "\n",
        "    predictions_train_actual = torch.tensor(scaler.inverse_transform(pred.detach()))\n",
        "    actual_train_error = criterion_training(predictions_train_actual, y_train_actual)\n",
        "\n",
        "    loss = criterion_training(pred, y_train)\n",
        "    # Update model here based on error\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test data\n",
        "    with torch.no_grad():\n",
        "      # Evaluate the model here.\n",
        "      pred_test = model(X_test)\n",
        "      loss_test = criterion_testing(pred_test, y_test)\n",
        "\n",
        "      predictions_test_actual = torch.tensor(scaler.inverse_transform(pred_test.detach()))\n",
        "      actual_test_error = criterion_testing(predictions_test_actual, y_test_actual)\n",
        "\n",
        "    #defining a best model\n",
        "    if actual_test_error < best_test_error:\n",
        "        best_test_error = actual_test_error\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "    if epoch %10 == 0:\n",
        "      print(f\"Epoch {epoch}: Training Actual Error= {actual_train_error}, Test Actual Error= {actual_test_error}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ea856b-bc58-484d-dfe1-150ff7beae1b",
        "id": "FkaCrR2FlCPy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training Actual Error= 22.369378874675053, Test Actual Error= 20.779999945224876\n",
            "Epoch 10: Training Actual Error= 10.354660874129321, Test Actual Error= 9.886283691427657\n",
            "Epoch 20: Training Actual Error= 4.635412255986947, Test Actual Error= 2.8538468638244887\n",
            "Epoch 30: Training Actual Error= 3.4021981384067383, Test Actual Error= 2.8290811942056124\n",
            "Epoch 40: Training Actual Error= 3.4023658270637824, Test Actual Error= 3.8123779873499695\n",
            "Epoch 50: Training Actual Error= 3.2159951982009156, Test Actual Error= 2.9748699184628196\n",
            "Epoch 60: Training Actual Error= 3.1361548903229317, Test Actual Error= 3.098536405098057\n",
            "Epoch 70: Training Actual Error= 3.116827107207867, Test Actual Error= 3.196229464996828\n",
            "Epoch 80: Training Actual Error= 3.0955141109022306, Test Actual Error= 3.0327859790511282\n",
            "Epoch 90: Training Actual Error= 3.067172462731226, Test Actual Error= 3.075549531916239\n",
            "Epoch 100: Training Actual Error= 3.040365540824293, Test Actual Error= 3.064486638767004\n",
            "Epoch 110: Training Actual Error= 3.0126092267684026, Test Actual Error= 3.0144623507534503\n",
            "Epoch 120: Training Actual Error= 2.9836632272247083, Test Actual Error= 2.991291598278488\n",
            "Epoch 130: Training Actual Error= 2.9537411504324584, Test Actual Error= 2.9723909294956274\n",
            "Epoch 140: Training Actual Error= 2.9226740117749554, Test Actual Error= 2.9457572767649487\n",
            "Epoch 150: Training Actual Error= 2.8904094465258927, Test Actual Error= 2.9169946938637556\n",
            "Epoch 160: Training Actual Error= 2.8568762573939375, Test Actual Error= 2.888413336916695\n",
            "Epoch 170: Training Actual Error= 2.821801526556384, Test Actual Error= 2.8595182030485735\n",
            "Epoch 180: Training Actual Error= 2.7847785191216947, Test Actual Error= 2.8305232836617655\n",
            "Epoch 190: Training Actual Error= 2.7459202128594375, Test Actual Error= 2.800122111430218\n",
            "Epoch 200: Training Actual Error= 2.7057571824884947, Test Actual Error= 2.7706371047831944\n",
            "Epoch 210: Training Actual Error= 2.664722360900364, Test Actual Error= 2.7413722263203053\n",
            "Epoch 220: Training Actual Error= 2.623507515852018, Test Actual Error= 2.7136536172702916\n",
            "Epoch 230: Training Actual Error= 2.583188668704148, Test Actual Error= 2.687469886465039\n",
            "Epoch 240: Training Actual Error= 2.5449573283582687, Test Actual Error= 2.663862512861745\n",
            "Epoch 250: Training Actual Error= 2.5090683626090575, Test Actual Error= 2.640261563990934\n",
            "Epoch 260: Training Actual Error= 2.4756652267253463, Test Actual Error= 2.6200597770213903\n",
            "Epoch 270: Training Actual Error= 2.444717746343403, Test Actual Error= 2.602325768870342\n",
            "Epoch 280: Training Actual Error= 2.416313782930741, Test Actual Error= 2.5877762338026193\n",
            "Epoch 290: Training Actual Error= 2.390650257774156, Test Actual Error= 2.5759299399549684\n",
            "Epoch 300: Training Actual Error= 2.3678348899127104, Test Actual Error= 2.567044891356611\n",
            "Epoch 310: Training Actual Error= 2.3480033082975984, Test Actual Error= 2.5605937265039715\n",
            "Epoch 320: Training Actual Error= 2.3310140500587195, Test Actual Error= 2.555578853832607\n",
            "Epoch 330: Training Actual Error= 2.316463185177216, Test Actual Error= 2.551666820128373\n",
            "Epoch 340: Training Actual Error= 2.303852037915459, Test Actual Error= 2.5471033553880678\n",
            "Epoch 350: Training Actual Error= 2.2926521467265957, Test Actual Error= 2.5418474298306784\n",
            "Epoch 360: Training Actual Error= 2.2824164743505717, Test Actual Error= 2.5358541651667155\n",
            "Epoch 370: Training Actual Error= 2.2729809305020514, Test Actual Error= 2.529455366368974\n",
            "Epoch 380: Training Actual Error= 2.26421195698588, Test Actual Error= 2.5228036593984653\n",
            "Epoch 390: Training Actual Error= 2.256032030764363, Test Actual Error= 2.5161064423951243\n",
            "Epoch 400: Training Actual Error= 2.248389662498362, Test Actual Error= 2.509469973955515\n",
            "Epoch 410: Training Actual Error= 2.241222413135379, Test Actual Error= 2.5029070217761022\n",
            "Epoch 420: Training Actual Error= 2.2345013968383713, Test Actual Error= 2.496493886814692\n",
            "Epoch 430: Training Actual Error= 2.2282247664502197, Test Actual Error= 2.4904678987112145\n",
            "Epoch 440: Training Actual Error= 2.222323656798752, Test Actual Error= 2.484799254269093\n",
            "Epoch 450: Training Actual Error= 2.2167820972543035, Test Actual Error= 2.4793272713994066\n",
            "Epoch 460: Training Actual Error= 2.211602095475813, Test Actual Error= 2.474225968320762\n",
            "Epoch 470: Training Actual Error= 2.2067063244479272, Test Actual Error= 2.4694533794052327\n",
            "Epoch 480: Training Actual Error= 2.2020613058470824, Test Actual Error= 2.4649989925137548\n",
            "Epoch 490: Training Actual Error= 2.197633573881792, Test Actual Error= 2.4607540789649756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "relu is worse because of dead neuron problem"
      ],
      "metadata": {
        "id": "4DDHnRMf2EAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN"
      ],
      "metadata": {
        "id": "YWubkiJ-4Mgw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "juNQf_0T4RxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sea_variables.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVJ9UgYYptln",
        "outputId": "b7c77db3-0db5-42e1-fc8e-6c23034df4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 345646 entries, 0 to 345645\n",
            "Data columns (total 12 columns):\n",
            " #   Column                    Non-Null Count   Dtype  \n",
            "---  ------                    --------------   -----  \n",
            " 0   month                     345646 non-null  int64  \n",
            " 1   day                       345646 non-null  int64  \n",
            " 2   timestamp                 345646 non-null  object \n",
            " 3   avg_sea_surface_temp      345646 non-null  float64\n",
            " 4   avg_wind_direction_true   200954 non-null  float64\n",
            " 5   avg_wind_speed            200622 non-null  float64\n",
            " 6   avg_visibility            18775 non-null   float64\n",
            " 7   avg_sea_level_pressure    198507 non-null  float64\n",
            " 8   avg_air_temperature       204296 non-null  float64\n",
            " 9   avg_wetbulb_temperature   15669 non-null   float64\n",
            " 10  avg_dewpoint_temperature  141826 non-null  float64\n",
            " 11  avg_total_cloud_amount    11877 non-null   float64\n",
            "dtypes: float64(9), int64(2), object(1)\n",
            "memory usage: 31.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sea_variables.isna().sum() / len(sea_variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoxEd8Rupv4V",
        "outputId": "06f92014-6e27-4899-9473-4d6966b17d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month                       0.000000\n",
              "day                         0.000000\n",
              "timestamp                   0.000000\n",
              "avg_sea_surface_temp        0.000000\n",
              "avg_wind_direction_true     0.418613\n",
              "avg_wind_speed              0.419574\n",
              "avg_visibility              0.945681\n",
              "avg_sea_level_pressure      0.425693\n",
              "avg_air_temperature         0.408944\n",
              "avg_wetbulb_temperature     0.954667\n",
              "avg_dewpoint_temperature    0.589678\n",
              "avg_total_cloud_amount      0.965638\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sea_variables = sea_variables.drop(columns=[\"timestamp\"])"
      ],
      "metadata": {
        "id": "FlrGkqmkYqDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_agg_df = sea_variables.groupby([\"month\", \"day\"]).mean().reset_index()"
      ],
      "metadata": {
        "id": "wa_7eoRyYyGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_agg_df.isna().sum() / len(day_agg_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9JSQ1jGZITN",
        "outputId": "0f7c3537-167d-4ed1-a0b3-10237377b692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month                       0.0\n",
              "day                         0.0\n",
              "avg_sea_surface_temp        0.0\n",
              "avg_wind_direction_true     0.0\n",
              "avg_wind_speed              0.0\n",
              "avg_visibility              0.0\n",
              "avg_sea_level_pressure      0.0\n",
              "avg_air_temperature         0.0\n",
              "avg_wetbulb_temperature     0.0\n",
              "avg_dewpoint_temperature    0.0\n",
              "avg_total_cloud_amount      0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "day_agg_df = day_agg_df.drop(columns=[\"month\", \"day\"])"
      ],
      "metadata": {
        "id": "osU0hw6RbMNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_agg_df[\"avg_sea_surface_temp\"] = day_agg_df[\"avg_sea_surface_temp\"].shift(periods=1)"
      ],
      "metadata": {
        "id": "JtPxra9UE6O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "day_agg_df = day_agg_df.dropna()"
      ],
      "metadata": {
        "id": "VBfjgWoqHHLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = day_agg_df.drop(\"avg_sea_surface_temp\", axis=1)\n",
        "y = day_agg_df[\"avg_sea_surface_temp\"].copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "C_2LPUkTbYoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "forest_reg = make_pipeline(std_scaler, RandomForestRegressor(random_state=42))\n",
        "\n",
        "forest_reg.fit(X_train, y_train)\n",
        "y_train_predictions = forest_reg.predict(X_train)\n",
        "forest_mae = mean_absolute_error(y_train, y_train_predictions)\n",
        "\n",
        "print(f\"The training data MAE is {forest_mae} or about {(forest_mae/y_train.mean()*100):.0f}% error\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiivazjZb-Lv",
        "outputId": "d395524d-24a9-4ddc-91e5-78ff40a72db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training data MAE is 0.11045997393791644 or about 1% error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predictions = forest_reg.predict(X_test)\n",
        "forest_test_mae = mean_absolute_error(y_test, y_test_predictions)\n",
        "\n",
        "print(f\"The test data MAE is {forest_test_mae} or about {(forest_test_mae/y_test.mean()*100):.0f}% error\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3phBl6KeG63",
        "outputId": "d1a7e400-e07b-4d4a-f59f-5443890c59e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test data MAE is 0.2449696002364195 or about 1% error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_distribs = {'randomforestregressor__max_depth': randint(low=1, high=50),\n",
        "                  'randomforestregressor__min_samples_leaf': randint(low=1, high=20)}\n",
        "\n",
        "rnd_search = RandomizedSearchCV(\n",
        "    forest_reg, param_distributions=param_distribs, n_iter=50, cv=3,\n",
        "    scoring='neg_mean_absolute_error', random_state=42)\n",
        "\n",
        "rnd_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9TCXpKz5sDVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_res = pd.DataFrame(rnd_search.cv_results_)\n",
        "rnd_res.sort_values(by=\"mean_test_score\", ascending=False, inplace=True)\n",
        "rnd_res.filter(regex = '(^param_|mean_test_score)', axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "g0FbE0botRXV",
        "outputId": "47b1569f-4064-47d2-cd81-0718b1434087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   param_randomforestregressor__max_depth  \\\n",
              "6                                      22   \n",
              "15                                     44   \n",
              "5                                      40   \n",
              "4                                      11   \n",
              "9                                       2   \n",
              "8                                      30   \n",
              "19                                      4   \n",
              "14                                     15   \n",
              "0                                      39   \n",
              "13                                     28   \n",
              "2                                      21   \n",
              "3                                      19   \n",
              "7                                      24   \n",
              "10                                     12   \n",
              "12                                     27   \n",
              "1                                      43   \n",
              "17                                      7   \n",
              "11                                     25   \n",
              "18                                     39   \n",
              "16                                     37   \n",
              "\n",
              "   param_randomforestregressor__min_samples_leaf  mean_test_score  \n",
              "6                                              2        -0.337453  \n",
              "15                                             3        -0.341983  \n",
              "5                                              3        -0.341983  \n",
              "4                                              4        -0.345648  \n",
              "9                                              1        -0.346375  \n",
              "8                                              6        -0.351201  \n",
              "19                                            14        -0.351309  \n",
              "14                                            15        -0.351973  \n",
              "0                                             15        -0.351973  \n",
              "13                                            16        -0.353105  \n",
              "2                                              7        -0.355223  \n",
              "3                                             11        -0.358461  \n",
              "7                                             12        -0.360170  \n",
              "10                                            12        -0.360170  \n",
              "12                                            10        -0.360249  \n",
              "1                                              8        -0.360362  \n",
              "17                                             9        -0.361578  \n",
              "11                                            17        -0.377908  \n",
              "18                                            18        -0.418355  \n",
              "16                                            19        -0.472191  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a7d3bfc-b09d-41f4-880a-517240356f25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_randomforestregressor__max_depth</th>\n",
              "      <th>param_randomforestregressor__min_samples_leaf</th>\n",
              "      <th>mean_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.337453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>44</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.341983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.341983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.345648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.346375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.351201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>-0.351309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.351973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.351973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>-0.353105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.355223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>-0.358461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>24</td>\n",
              "      <td>12</td>\n",
              "      <td>-0.360170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>-0.360170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>-0.360249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.360362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.361578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>25</td>\n",
              "      <td>17</td>\n",
              "      <td>-0.377908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>39</td>\n",
              "      <td>18</td>\n",
              "      <td>-0.418355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>37</td>\n",
              "      <td>19</td>\n",
              "      <td>-0.472191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a7d3bfc-b09d-41f4-880a-517240356f25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a7d3bfc-b09d-41f4-880a-517240356f25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a7d3bfc-b09d-41f4-880a-517240356f25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-66ab68ea-a6f6-4cf6-ada5-9440e6e32864\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66ab68ea-a6f6-4cf6-ada5-9440e6e32864')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-66ab68ea-a6f6-4cf6-ada5-9440e6e32864 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"rnd_res\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"param_randomforestregressor__max_depth\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 2,\n        \"max\": 44,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          22,\n          30,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"param_randomforestregressor__min_samples_leaf\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 1,\n        \"max\": 19,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          2,\n          3,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.030824637915806936,\n        \"min\": -0.4721909810072639,\n        \"max\": -0.3374532835445365,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -0.3374532835445365,\n          -0.3419829975789324,\n          -0.3513094402831702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#help hyperparameter tuning made the model worse but the bones are here ig"
      ],
      "metadata": {
        "id": "a5JaYvnDt0s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1"
      ],
      "metadata": {
        "id": "cJ7NWG3T4Yuy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding more variabes to RNN/MLP"
      ],
      "metadata": {
        "id": "PAEJqpR64UVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bennett: Start running from here"
      ],
      "metadata": {
        "id": "MazMrcaabL8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sequences\n",
        "sequence_length = 99\n",
        "\n",
        "def create_sequences(data, sequence_length):\n",
        "\n",
        "  total_sequence=[]\n",
        "  prices = []\n",
        "\n",
        "  for day in range(0, (len(data) - sequence_length)):\n",
        "    start_index = day\n",
        "    end_index = sequence_length + day\n",
        "    day_sequence = data[start_index:end_index]\n",
        "    day_price = data[end_index]\n",
        "\n",
        "    total_sequence.append(day_sequence)\n",
        "    prices.append(day_price)\n",
        "  return np.array(total_sequence), np.array(prices)\n",
        "\n",
        "sequences = create_sequences(scaled_data, sequence_length)\n",
        "X = sequences[0]\n",
        "y = sequences[1]"
      ],
      "metadata": {
        "id": "TmGKlCcMM-2Z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(X.shape[0]* split_ratio)\n",
        "X_train = torch.tensor(X[:train_size]).float()\n",
        "y_train = torch.tensor(y[:train_size]).float()\n",
        "X_test = torch.tensor(X[train_size:]).float()\n",
        "y_test = torch.tensor(y[train_size:]).float()"
      ],
      "metadata": {
        "id": "WK1izF4ONCxy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyIQWPupNMff",
        "outputId": "f6744f54-f533-4f5c-95be-2b4ac6e549c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([276437, 99, 1]),\n",
              " torch.Size([69110, 99, 1]),\n",
              " torch.Size([276437, 1]),\n",
              " torch.Size([69110, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # Forward propagate RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Example usage:\n",
        "# Define input parameters\n",
        "input_size = 1  # Number of features in input data (e.g., time series)\n",
        "hidden_size = 20  # Number of hidden units in the RNN\n",
        "num_layers = 2  # Number of RNN layers\n",
        "output_size = 1  # Number of features in output data (e.g., regression target)\n",
        "\n",
        "# Instantiate the model\n",
        "model = RNN(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XZp-3AiJmiS",
        "outputId": "124fa0f2-87f5-45c9-dd08-3c4ac54755cd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(1, 10, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.L1Loss()  # Mean Absolute Error (MAE) loss\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Calculate MAE loss on the training set\n",
        "with torch.no_grad():\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    outputs = model(X_train)\n",
        "    mae_loss = criterion(outputs, y_train)\n",
        "    print(f'MAE Loss on Training Set: {mae_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5TMFihkNUno",
        "outputId": "7f4e5789-1991-4f85-92ee-16e28e720141"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8694\n",
            "Epoch [2/10], Loss: 0.8577\n",
            "Epoch [3/10], Loss: 0.8460\n",
            "Epoch [4/10], Loss: 0.8345\n",
            "Epoch [5/10], Loss: 0.8230\n",
            "Epoch [6/10], Loss: 0.8116\n",
            "Epoch [7/10], Loss: 0.8004\n",
            "Epoch [8/10], Loss: 0.7892\n",
            "Epoch [9/10], Loss: 0.7781\n",
            "Epoch [10/10], Loss: 0.7670\n",
            "MAE Loss on Training Set: 0.7560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ZE8FGtqWS8Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train[0: 20000]\n",
        "# X_test = X_test[0: 5000]\n",
        "# y_train = y_train[0: 20000]\n",
        "# y_test = y_test[0: 5000]"
      ],
      "metadata": {
        "id": "-1V8d7NTT6WV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the LSTM model\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Example usage:\n",
        "# Define input parameters\n",
        "input_size = 1  # Number of features in input data (e.g., time series)\n",
        "hidden_size = 20  # Number of hidden units in the LSTM\n",
        "num_layers = 2  # Number of LSTM layers\n",
        "output_size = 1  # Number of features in output data (e.g., regression target)\n",
        "\n",
        "# Instantiate the model\n",
        "model = LSTM(input_size, hidden_size, num_layers, output_size)\n",
        "\n",
        "# Print model architecture\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KZ4MpTsS4g0",
        "outputId": "96ba904b-80ef-4808-d134-47b665e16c81"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(1, 10, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=10, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.L1Loss()  # Mean Absolute Error (MAE) loss\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Calculate MAE loss on the training set\n",
        "with torch.no_grad():\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    outputs = model(X_train)\n",
        "    mae_loss = criterion(outputs, y_train)\n",
        "    print(f'MAE Loss on Training Set: {mae_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBVbvZoFS1Mg",
        "outputId": "ffdc222d-c964-4c76-c01c-a1c667644d45"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.5752\n",
            "Epoch [2/10], Loss: 0.5680\n",
            "Epoch [3/10], Loss: 0.5610\n",
            "Epoch [4/10], Loss: 0.5539\n",
            "Epoch [5/10], Loss: 0.5469\n",
            "Epoch [6/10], Loss: 0.5399\n",
            "Epoch [7/10], Loss: 0.5330\n",
            "Epoch [8/10], Loss: 0.5260\n",
            "Epoch [9/10], Loss: 0.5191\n",
            "Epoch [10/10], Loss: 0.5122\n",
            "MAE Loss on Training Set: 0.5053\n"
          ]
        }
      ]
    }
  ]
}